{"cells":[{"cell_type":"markdown","source":["# Press the play button and go through the Google process."],"metadata":{"id":"kKO269luWn-S"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","! pip install git+https://github.com/openai/whisper.git\n","! pip install jiwer\n","import os\n","import numpy as np\n","\n","try:\n","    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n","except ImportError:\n","    pass\n","\n","import torch\n","import pandas as pd\n","import whisper\n","\n","from tqdm.notebook import tqdm\n","\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = whisper.load_model(\"large\")\n","print(\n","    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n","    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",")\n","\n","def transcribe(file_name, language, translate=None):\n","  path = 'drive/MyDrive/CRG interviews/'\n","  new_file_name = file_name.split('.')[0]\n","\n","  transcribed = model.transcribe(path + file_name, language=language)[\"text\"]\n","  with open(f'/content/drive/My Drive/CRG interviews/{new_file_name}_transcribed.txt', 'w') as f:\n","    f.write(transcribed)\n","\n","  if translate != None:\n","    translated = model.transcribe(path + file_name, language=language, task='translate')[\"text\"]\n","    with open(f'/content/drive/My Drive/CRG interviews/{new_file_name}_translated.txt', 'w') as f:\n","      f.write(translated)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4dkyrU8G0yC","executionInfo":{"status":"ok","timestamp":1684942708583,"user_tz":-120,"elapsed":129353,"user":{"displayName":"Dana Rentenaar","userId":"06032166999368442156"}},"outputId":"4a073465-dc77-409b-f947-7db3ca424161"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-c6glxaby\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-c6glxaby\n","  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n","Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n","  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.5)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798075 sha256=0c737ffe452aa851cb582cb3f075d83130b27206a4cd479808b63df5935c614b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-m5ush7ue/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: tiktoken, openai-whisper\n","Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jiwer\n","  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.3)\n","Collecting rapidfuzz==2.13.7 (from jiwer)\n","  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n","Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████| 2.87G/2.87G [00:26<00:00, 115MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model is multilingual and has 1,541,384,960 parameters.\n"]}]},{"cell_type":"markdown","source":["# For English transcription"],"metadata":{"id":"Tzz-F3NdYqjM"}},{"cell_type":"code","source":["transcribe('tala.m4a', language='English')"],"metadata":{"id":"9HxNoZwCMc7a","executionInfo":{"status":"ok","timestamp":1684943056900,"user_tz":-120,"elapsed":348330,"user":{"displayName":"Dana Rentenaar","userId":"06032166999368442156"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# For transcription and translation to English"],"metadata":{"id":"SSqFUxeNYvRP"}},{"cell_type":"code","source":["transcribe('samir.wav', language = 'Arabic', translate=True)"],"metadata":{"id":"7EIVIRgwYuPd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vergeet niet de sessie te beeindigen!!!"],"metadata":{"id":"fhFnKVSCZYkN"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb","timestamp":1684937415029}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
